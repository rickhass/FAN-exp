G.Table200 <- subset(G.Tab, select = c(carage1,nonhits,hits))
G.Table200$hit.200 <- G.Table200$hits / (G.Table200$hits + G.Table200$nonhits)
rm(G.T,G.Tab)
#make full ratios table
year <- unique(G$historical.time)
G.ratios <- cbind(year,subset(G.Table10, select = c(carage1,hit.10)), subset(G.Table20, select = c(hit.20)), subset(G.Table50, select = c(hit.50)), subset(G.Table100, select = c(hit.100)), subset (G.Table200, select = c(hit.200)))
G.ratios$carage1 <- as.numeric(G.ratios$carage1)
rm(year)
#now add citation index..average citation per year
G$cit.index <- (G$Total / 6)
G.cit.index <- matrix(data= NA, 25,1)
for(i in 1:25){
G.cit.index[i] <- mean(subset(G$Total,G$career.age == i))
}
G.ratios$cit <- subset(G.cit.index, G.cit.index != "NaN") #adds it to above
G.ratios$comp <- rep("Gershwin")
#clear space
rm(G.Table10,G.Table100,G.Table20,G.Table200,G.Table50,G.cit.index)
#Kern
#10
K.T <- table(K$career.age,K$hit.10)
K.T <- data.frame(K.T)
K.Tab <- cbind(K.T[1:41,],K.T[42:82,])
colnames(K.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
K.Table10 <- subset(K.Tab, select = c(carage1,nonhits,hits))
K.Table10$hit.10 <- K.Table10$hits / (K.Table10$hits + K.Table10$nonhits)
rm(K.T,K.Tab)
#20
K.T <- table(K$career.age,K$hit.20)
K.T <- data.frame(K.T)
K.Tab <- cbind(K.T[1:41,],K.T[42:82,])
colnames(K.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
K.Table20 <- subset(K.Tab, select = c(carage1,nonhits,hits))
K.Table20$hit.20 <- K.Table20$hits / (K.Table20$hits + K.Table20$nonhits)
rm(K.T,K.Tab)
#50
K.T <- table(K$career.age,K$hit.50)
K.T <- data.frame(K.T)
K.Tab <- cbind(K.T[1:41,],K.T[42:82,])
colnames(K.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
K.Table50 <- subset(K.Tab, select = c(carage1,nonhits,hits))
K.Table50$hit.50 <- K.Table50$hits / (K.Table50$hits + K.Table50$nonhits)
rm(K.T,K.Tab)
#100
K.T <- table(K$career.age,K$hit.100)
K.T <- data.frame(K.T)
K.Tab <- cbind(K.T[1:41,],K.T[42:82,])
colnames(K.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
K.Table100 <- subset(K.Tab, select = c(carage1,nonhits,hits))
K.Table100$hit.100 <- K.Table100$hits / (K.Table100$hits + K.Table100$nonhits)
rm(K.T,K.Tab)
#200
K.T <- table(K$career.age,K$hit.200)
K.T <- data.frame(K.T)
K.Tab <- cbind(K.T[1:41,],K.T[42:82,])
colnames(K.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
K.Table200 <- subset(K.Tab, select = c(carage1,nonhits,hits))
K.Table200$hit.200 <- K.Table200$hits / (K.Table200$hits + K.Table200$nonhits)
rm(K.T,K.Tab)
#full table
year <- unique(K$historical.time)
K.ratios <- cbind(year, subset(K.Table10, select = c(carage1,hit.10)), subset(K.Table20, select = c(hit.20)), subset(K.Table50, select = c(hit.50)), subset(K.Table100, select = c(hit.100)), subset(K.Table200, select = c(hit.200)))
K.ratios$carage1 <- as.numeric(K.ratios$carage1)
rm(year)
#now add citation index..average citation per year
K$cit.index <- (K$Total / 6)
K.cit.index <- matrix(data= NA, 55,1)
for(i in 1:55){
K.cit.index[i] <- mean(subset(K$Total,K$career.age == i))
}
K.ratios$cit <- subset(K.cit.index, K.cit.index != "NaN") #adds it to above
K.ratios$comp <- rep("Kern")
#clear space
rm(K.Table10,K.Table100,K.Table20,K.Table200,K.Table50,K.cit.index)
#Porter
#10
P.T <- table(P$career.age,P$hit.10)
P.T <- data.frame(P.T)
P.Tab <- cbind(P.T[1:44,],P.T[45:88,])
colnames(P.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
P.Table10 <- subset(P.Tab, select = c(carage1,nonhits,hits))
P.Table10$hit.10 <- P.Table10$hits / (P.Table10$hits + P.Table10$nonhits)
rm(P.T,P.Tab)
#20
P.T <- table(P$career.age,P$hit.20)
P.T <- data.frame(P.T)
P.Tab <- cbind(P.T[1:44,],P.T[45:88,])
colnames(P.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
P.Table20 <- subset(P.Tab, select = c(carage1,nonhits,hits))
P.Table20$hit.20 <- P.Table20$hits / (P.Table20$hits + P.Table20$nonhits)
rm(P.T,P.Tab)
#50
P.T <- table(P$career.age,P$hit.50)
P.T <- data.frame(P.T)
P.Tab <- cbind(P.T[1:44,],P.T[45:88,])
colnames(P.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
P.Table50 <- subset(P.Tab, select = c(carage1,nonhits,hits))
P.Table50$hit.50 <- P.Table50$hits / (P.Table50$hits + P.Table50$nonhits)
rm(P.T,P.Tab)
#100
P.T <- table(P$career.age,P$hit.100)
P.T <- data.frame(P.T)
P.Tab <- cbind(P.T[1:44,],P.T[45:88,])
colnames(P.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
P.Table100 <- subset(P.Tab, select = c(carage1,nonhits,hits))
P.Table100$hit.100 <- P.Table100$hits / (P.Table100$hits + P.Table100$nonhits)
rm(P.T,P.Tab)
#200
P.T <- table(P$career.age,P$hit.200)
P.T <- data.frame(P.T)
P.Tab <- cbind(P.T[1:44,],P.T[45:88,])
colnames(P.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
P.Table200 <- subset(P.Tab, select = c(carage1,nonhits,hits))
P.Table200$hit.200 <- P.Table200$hits / (P.Table200$hits + P.Table200$nonhits)
rm(P.T,P.Tab)
#make full ratios table
year <- unique(P$historical.time)
P.ratios <- cbind(year,subset(P.Table10, select = c(carage1,hit.10)), subset(P.Table20, select = c(hit.20)), subset(P.Table50, select = c(hit.50)), subset(P.Table100, select = c(hit.100)), subset (P.Table200, select = c(hit.200)))
P.ratios$carage1 <- as.numeric(P.ratios$carage1)
rm(year)
#now add citation index..average citation per year
P$cit.index <- (P$Total / 6)
P.cit.index <- matrix(data= NA, 50,1)
for(i in 1:50){
P.cit.index[i] <- mean(subset(P$Total,P$career.age == i))
}
P.ratios$cit <- subset(P.cit.index, P.cit.index != "NaN") #adds it to above
P.ratios$comp <- rep("Porter")
#clear space
rm(P.Table10,P.Table100,P.Table20,P.Table200,P.Table50,P.cit.index)
#Rodgers
#10
R.T <- table(R$career.age,R$hit.10)
R.T <- data.frame(R.T)
R.Tab <- cbind(R.T[1:41,],R.T[42:82,])
colnames(R.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
R.Table10 <- subset(R.Tab, select = c(carage1,nonhits,hits))
R.Table10$hit.10 <- R.Table10$hits / (R.Table10$hits + R.Table10$nonhits)
rm(R.T,R.Tab)
#20
R.T <- table(R$career.age,R$hit.20)
R.T <- data.frame(R.T)
R.Tab <- cbind(R.T[1:41,],R.T[42:82,])
colnames(R.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
R.Table20 <- subset(R.Tab, select = c(carage1,nonhits,hits))
R.Table20$hit.20 <- R.Table20$hits / (R.Table20$hits + R.Table20$nonhits)
rm(R.T,R.Tab)
#50
R.T <- table(R$career.age,R$hit.50)
R.T <- data.frame(R.T)
R.Tab <- cbind(R.T[1:41,],R.T[42:82,])
colnames(R.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
R.Table50 <- subset(R.Tab, select = c(carage1,nonhits,hits))
R.Table50$hit.50 <- R.Table50$hits / (R.Table50$hits + R.Table50$nonhits)
rm(R.T,R.Tab)
#100
R.T <- table(R$career.age,R$hit.100)
R.T <- data.frame(R.T)
R.Tab <- cbind(R.T[1:41,],R.T[42:82,])
colnames(R.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
R.Table100 <- subset(R.Tab, select = c(carage1,nonhits,hits))
R.Table100$hit.100 <- R.Table100$hits / (R.Table100$hits + R.Table100$nonhits)
rm(R.T,R.Tab)
#200
R.T <- table(R$career.age,R$hit.200)
R.T <- data.frame(R.T)
R.Tab <- cbind(R.T[1:41,],R.T[42:82,])
colnames(R.Tab) <- c("carage1","h1","nonhits","car2","h2","hits")
R.Table200 <- subset(R.Tab, select = c(carage1,nonhits,hits))
R.Table200$hit.200 <- R.Table200$hits / (R.Table200$hits + R.Table200$nonhits)
rm(R.T,R.Tab)
#make full ratios table
year <- unique(R$historical.time)
R.ratios <- cbind(year,subset(R.Table10, select = c(carage1,hit.10)), subset(R.Table20, select = c(hit.20)), subset(R.Table50, select = c(hit.50)), subset(R.Table100, select = c(hit.100)), subset (R.Table200, select = c(hit.200)))
R.ratios$carage1 <- as.numeric(R.ratios$carage1)
rm(year)
#now add citation index..average citation per year
R$cit.index <- (R$Total / 6)
R.cit.index <- matrix(data= NA, 61,1)
for(i in 1:61){
R.cit.index[i] <- mean(subset(R$Total,R$career.age == i))
}
R.ratios$cit <- subset(R.cit.index, R.cit.index != "NaN") #adds it to above
R.ratios$comp <- rep("Rodgers")
#clear space
rm(R.Table10,R.Table100,R.Table20,R.Table200,R.Table50,R.cit.index)
# Time series plot template
# plot(hit.10 ~ carage1, type = "o", pch = 16, data = B.ratios, xlab = "Year in career", ylab = "Hit Ratio (Recording Threshold = 10)")
comp.data <- rbind(B.ratios,G.ratios,K.ratios,P.ratios,R.ratios)
comp.data$composer <- as.factor(comp.data$comp)
comp.data <- comp.data[,-9]
# aggregate temp
# first make composer variable
# ggplot(comp.data, aes(carage1, cit)) + geom_point(aes(shape = comp)) +scale_shape(solid = F) + labs(x="Year in Career", y = "Citation Index")
dummy <- dummy.code(comp.data$composer)
colnames(dummy) <- c("Berlin","Gershwin","Kern","Porter","Rodgers")
cor.data <- cbind(comp.data[,1:8],dummy)
# partial correlations - only 4 covariate dummies
View(cor.data)
pool <- plm(hit.10 ~ poly(carage1,2), data = comp.data, index = c("composer","year"), model = "within")
summary(pool)
ggplot(comp.data, aes(carage1, cit)) + geom_point(aes(shape = comp)) +scale_shape(solid = F) + labs(x="Year in Career", y = "Citation Index")
comp.data <- rbind(B.ratios,G.ratios,K.ratios,P.ratios,R.ratios)
comp.data$composer <- as.factor(comp.data$comp)
comp.data <- comp.data[,-9]
# aggregate temp
# first make composer variable
ggplot(comp.data, aes(carage1, cit)) + geom_point(aes(shape = comp)) +scale_shape(solid = F) + labs(x="Year in Career", y = "Citation Index")
plot(hit.10 ~ carage1, type = "o", pch = 16, data = B.ratios, xlab = "Year in career", ylab = "Hit Ratio (Recording Threshold = 10)")
B.run <- read.xls("./Documents/RESEARCH/Data and Materials/Popular Song Archival/AMGvArchival.xls", sheet = 2)
G.run <- read.xls("./Documents/RESEARCH/Data and Materials/Popular Song Archival/AMGvArchival.xls", sheet = 3)
K.run <- read.xls("./Documents/RESEARCH/Data and Materials/Popular Song Archival/AMGvArchival.xls", sheet = 4)
P.run <- read.xls("./Documents/RESEARCH/Data and Materials/Popular Song Archival/AMGvArchival.xls", sheet = 5)
R.run <- read.xls("./Documents/RESEARCH/Data and Materials/Popular Song Archival/AMGvArchival.xls", sheet = 6)
#make data for combined scatter with comoposer as factor
B.run$Composer <- rep("Berlin", 19)
G.run$Composer <- rep("Gershwin", 25)
K.run$Composer <- rep("Kern", 37)
P.run$Composer <- rep("Porter", 24)
R.run$Composer <- rep("Rodgers", 38)
B.run <- B.run[,-1]
G.run <- G.run[,-1]
K.run <- K.run[,-1]
P.run <- P.run[,-1]
R.run <- R.run[,-1]
runs <- data.frame(rbind(B.run,G.run,K.run,P.run,R.run))
runs$log <- log(runs$N.performances)
b = 1909
g = 1913
k = 1905
p = 1909
r = 1919
for (i in 1:nrow(runs)){
if (runs$Composer[i] == "Berlin"){
runs$career[i] = ((runs$opening.year[i] - b) + 1)
}
else if (runs$Composer[i] == "Gershwin"){
runs$career[i] = ((runs$opening.year[i] - g) + 1)
}
else if (runs$Composer[i] == "Kern"){
runs$career[i] = ((runs$opening.year[i] - k) + 1)
}
else if (runs$Composer[i] == "Porter"){
runs$career[i] = ((runs$opening.year[i] - p) + 1)
}
else
runs$career[i] = ((runs$opening.year[i] - r) + 1)
}
for (i in 1:nrow(runs)){
comp = runs$Composer[i]
runs$avgcareer[i] <- mean(runs$career[runs$Composer == comp])
}
for (i in 1:nrow(runs)){
comp = runs$Composer[i]
runs$carstart[i] <- min(runs$opening.year[runs$Composer == comp])
}
runs.null <- lme(log ~ 1, data = runs, random = (~1 | Composer))
runs.null2 <- gls(log ~ 1, data = runs)
runs.mod.quad <- lme(log ~ poly(career,2) + carstart, data = runs, random = (~ 1 | Composer), control=list(opt="optim"))
B.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 2)
G.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 3)
K.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 4)
P.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 5)
R.run <- read.xls("./Documents/RESEARCH/Project/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 6)
#make data for combined scatter with comoposer as factor
B.run$Composer <- rep("Berlin", 19)
G.run$Composer <- rep("Gershwin", 25)
K.run$Composer <- rep("Kern", 37)
P.run$Composer <- rep("Porter", 24)
R.run$Composer <- rep("Rodgers", 38)
B.run <- B.run[,-1]
G.run <- G.run[,-1]
K.run <- K.run[,-1]
P.run <- P.run[,-1]
R.run <- R.run[,-1]
runs <- data.frame(rbind(B.run,G.run,K.run,P.run,R.run))
runs$log <- log(runs$N.performances)
b = 1909
g = 1913
k = 1905
p = 1909
r = 1919
for (i in 1:nrow(runs)){
if (runs$Composer[i] == "Berlin"){
runs$career[i] = ((runs$opening.year[i] - b) + 1)
}
else if (runs$Composer[i] == "Gershwin"){
runs$career[i] = ((runs$opening.year[i] - g) + 1)
}
else if (runs$Composer[i] == "Kern"){
runs$career[i] = ((runs$opening.year[i] - k) + 1)
}
else if (runs$Composer[i] == "Porter"){
runs$career[i] = ((runs$opening.year[i] - p) + 1)
}
else
runs$career[i] = ((runs$opening.year[i] - r) + 1)
}
for (i in 1:nrow(runs)){
comp = runs$Composer[i]
runs$avgcareer[i] <- mean(runs$career[runs$Composer == comp])
}
for (i in 1:nrow(runs)){
comp = runs$Composer[i]
runs$carstart[i] <- min(runs$opening.year[runs$Composer == comp])
}
runs.null <- lme(log ~ 1, data = runs, random = (~1 | Composer))
runs.null2 <- gls(log ~ 1, data = runs)
runs.mod.quad <- lme(log ~ poly(career,2) + carstart, data = runs, random = (~ 1 | Composer), control=list(opt="optim"))
B.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 2)
G.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 3)
K.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 4)
P.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 5)
R.run <- read.xls("./Documents/RESEARCH/Projects/Music Analysis/Popular Song Archival/AMGvArchival.xls", sheet = 6)
#make data for combined scatter with comoposer as factor
B.run$Composer <- rep("Berlin", 19)
G.run$Composer <- rep("Gershwin", 25)
K.run$Composer <- rep("Kern", 37)
P.run$Composer <- rep("Porter", 24)
R.run$Composer <- rep("Rodgers", 38)
B.run <- B.run[,-1]
G.run <- G.run[,-1]
K.run <- K.run[,-1]
P.run <- P.run[,-1]
R.run <- R.run[,-1]
runs <- data.frame(rbind(B.run,G.run,K.run,P.run,R.run))
runs$log <- log(runs$N.performances)
b = 1909
g = 1913
k = 1905
p = 1909
r = 1919
for (i in 1:nrow(runs)){
if (runs$Composer[i] == "Berlin"){
runs$career[i] = ((runs$opening.year[i] - b) + 1)
}
else if (runs$Composer[i] == "Gershwin"){
runs$career[i] = ((runs$opening.year[i] - g) + 1)
}
else if (runs$Composer[i] == "Kern"){
runs$career[i] = ((runs$opening.year[i] - k) + 1)
}
else if (runs$Composer[i] == "Porter"){
runs$career[i] = ((runs$opening.year[i] - p) + 1)
}
else
runs$career[i] = ((runs$opening.year[i] - r) + 1)
}
for (i in 1:nrow(runs)){
comp = runs$Composer[i]
runs$avgcareer[i] <- mean(runs$career[runs$Composer == comp])
}
for (i in 1:nrow(runs)){
comp = runs$Composer[i]
runs$carstart[i] <- min(runs$opening.year[runs$Composer == comp])
}
runs.null <- lme(log ~ 1, data = runs, random = (~1 | Composer))
runs.null2 <- gls(log ~ 1, data = runs)
runs.mod.quad <- lme(log ~ poly(career,2) + carstart, data = runs, random = (~ 1 | Composer), control=list(opt="optim"))
runs.plot <- ggplot(runs, aes(opening.year,log))
runs.plot + geom_point(aes(shape=Composer)) + scale_shape(solid = F) + labs(x="Opening Year", y = "log(N Performances)")
xyplot(log ~ opening.year | Composer, data = runs)
require(lattice)
xyplot(log ~ opening.year | Composer, data = runs)
knitr::opts_chunk$set(out.width = "6in", out.height = "3in", echo = TRUE)
normal.dist <- as.integer(rnorm(50000, mean = 20, sd = 5))
hist(normal.dist, xlab = "BDI scores", main = "Population of BDI scores")
describe(normal.dist)
# samples of size 5
means5 <- vector("numeric",5000)
for (i in 1:5000){
x <- sample(normal.dist, 5)
means5[i] <- mean(x)
}
hist(means5, xlab = "Means of BDI scores N = 5", main = "Sampling Distribution N =5")
describe(means5)
citation("MCMCglmm")
wrong <- c(15, 12, 21, 15, 19, 11, 18, 15, 17, 7, 18, 10, 0, 15, 9, 18, 24)
grades <- 50 - wrong
hist(grades)
describe(grades)
require(psych)
describe(grades)
quantile(grades, probs = seq(0, 1.0, 10))
quantile(grades, probs = seq(0, 1.0, .10))
curve <- as.data.frame(grades)
for (i in 1:nrow(curve)){
if(curve$grades[i] < 30.2){
curves$letter[i] = "D"
} else if (curve$grades[i] >= 30.2 && curve$grades[i] < 33.8){
curve$letter[i] = "C"
} else if (curve$grades[i] >= 33.8 && cuvrve$grades[i] < 35){
curve$letter[i] = "C+"
} else if (curve$grades[i] >= 35 && curve$grades[i] < 38.2){
curve$letter[i] = "B-"
} else if (curve$grades[i] >= 38.2 && curve$grades[i] < 39.8){
curve$letter[i] = "B"
} else if (curve$grades[i] >= 39.8 && curve$grades[i] < 41.8){
curve$letter[i] = "B+"
} else {
curve$letter[i] = "A"
}
}
curve <- as.data.frame(grades)
for (i in 1:nrow(curve)){
if(curve$grades[i] < 30.2){
curve$letter[i] = "D"
} else if (curve$grades[i] >= 30.2 && curve$grades[i] < 33.8){
curve$letter[i] = "C"
} else if (curve$grades[i] >= 33.8 && curve$grades[i] < 35){
curve$letter[i] = "C+"
} else if (curve$grades[i] >= 35 && curve$grades[i] < 38.2){
curve$letter[i] = "B-"
} else if (curve$grades[i] >= 38.2 && curve$grades[i] < 39.8){
curve$letter[i] = "B"
} else if (curve$grades[i] >= 39.8 && curve$grades[i] < 41.8){
curve$letter[i] = "B+"
} else {
curve$letter[i] = "A"
}
}
View(curve)
30/50
source('~/Documents/Teaching/Intro Psych/Exams/exam2grades.R')
View(curve)
table(curve$letter)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/RESEARCH/Projects/JCIPE/JTOG")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/RESEARCH/Projects/JCIPE/JTOG")
library(gdata)
library(psych)
## need this
require(GPArotation)
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
library(knitr)
library(dplyr)
library(jsonlite)
setwd("~/psiturk-cig")
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
library(knitr)
library(dplyr)
library(jsonlite)
setwd("~/psiturk-cig")
DATABASE = 'testdata.db'
mturk.data <- dbConnect(RSQLite::SQLite(), dbname = DATABASE)
dbListTables(mturk.data)
View(mturk)
# mturk status codes:
# NOT_ACCEPTED = 0
# ALLOCATED = 1
# STARTED = 2
# COMPLETED = 3
# SUBMITTED = 4
# CREDITED = 5
# QUITEARLY = 6
# BONUSED = 7
# list of acceptable status codes
good.status = c(3, 4, 5, 7)
# list of workers you want to exclude (e.g. participated in other experiments even though you asked them not to)
# I use workerid and not uniqueid because I need to exclude based on participation in other experiments
exclude.workers = c()
# include only workers that have a good status code and aren't in our exclude list
mturk.data <- filter(mturk, status %in% good.status, !(workerid %in% exclude.workers))
View(mturk)
View(mturk.data)
# Add a column that is more descriptive of cond (0, 1) and make a table
# summarising how many participants were in each group
subj.info <- mutate(mturk.data, Condition = ifelse(cond == 0, "Condition 1", "Condition 2")) %>%
group_by(Condition, cond, counterbalance) %>%
summarise(N = n())
# show results in a pretty table
kable(subj.info)
# a function that pulls the trialdata from the data object of datastring
get_trial_data <- function(json_object){
# reads the datastring JSON object into an R data frame
df <- jsonlite::fromJSON(json_object, simplifyDataFrame = TRUE)
# stores data$trialdata from this data string as `data`
data <- df$data$trialdata
# adds the participant's uniqueid in case it wasn't added in experiment
data['uniqueid'] = df$data$uniqueid
# removes the df object and returns data
rm(df)
return(data)
}
# check to make sure your json_object is valid with
# jsonlite::validate()
# get the datastring field from the data table
datastring <- mturk.data$datastring
# get_trial_data from each JSON object (each subject) in datastring and make single dataframe
trialdata <- lapply(datastring, get_trial_data) %>%
bind_rows()
View(trialdata)
df <- jsonlite::fromJSON(datastring, simplifyDataFrame = TRUE)
questiondata <- lapply(datastring, get_question_data) %>%
bind_rows()
get_question_data <- function(json_object){
# reads the datastring JSON object into an R data frame
df <- jsonlite::fromJSON(json_object, simplifyDataFrame = TRUE)
# stores data$trialdata from this data string as `data`
data <- df$questiondata
# adds the participant's uniqueid in case it wasn't added in experiment
data['uniqueid'] = df$data$uniqueid
# removes the df object and returns data
rm(df)
return(data)
}
questiondata <- lapply(datastring, get_question_data) %>%
bind_rows()
View(questiondata)
